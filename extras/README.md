# Extras: Optional Quality-of-Life Additions

This folder contains optional files that users can copy into their own projects to enhance their development experience with this package.

**Important**: These files are templates for YOUR project, not part of the package itself. Copy and customize them as needed.

---

## What's Included

### dbt Integration

- **[sources.yml](dbt/sources.yml)** - Complete dbt source definitions for both `jaffle_shop` and `jaffle_crm` databases
  - All tables with column descriptions
  - Freshness checks configured
  - Ready to copy to your `models/` directory

- **[profiles.yml.example](dbt/profiles.yml.example)** - Profile templates for all 3 platforms (DuckDB, MotherDuck, Azure SQL)
  - Copy to `~/.dbt/profiles.yml`
  - Includes environment variable configuration
  - Examples for each target

### Data Quality

- **[Soda Core Contracts](soda/)** - Data quality checks for all tables
  - Schema validation
  - Foreign key integrity checks
  - SLA/freshness monitoring aligned with delta days
  - Soft delete validation
  - Configuration for all 3 platforms

### Developer Tools

- **[VS Code Tasks](vscode/tasks.json)** - Quick access to demo operations via Command Palette
  - Copy to your `.vscode/tasks.json`
  - Run operations with Cmd+Shift+P → "Tasks: Run Task"

- **[Makefile](scripts/Makefile)** - Common operations wrapped in make targets
  - `make baseline`, `make delta-1`, `make reset`, etc.
  - Workflow targets for common scenarios

- **[justfile](scripts/justfile)** - Modern alternative to Makefile
  - Better syntax, cleaner output
  - Same operations as Makefile

### CI/CD

- **[GitHub Actions](cicd/github-actions.yml)** - Example workflow for testing with demo sources
  - Load baseline → run models → apply deltas → test
  - Soda Core integration example
  - Matrix testing across platforms

---

## How to Use

### 1. dbt Sources

```bash
# Copy sources.yml to your project
cp extras/dbt/sources.yml models/staging/demo_source/sources.yml

# Customize database/schema names if needed
# Then reference in your models:
# {{ source('jaffle_shop', 'customers') }}
```

### 2. dbt Profiles

```bash
# Copy example to your profiles
cp extras/dbt/profiles.yml.example ~/.dbt/profiles.yml

# Customize the file for your environment
# - Choose your default target (dev, motherduck, or azure)
# - Update paths/settings as needed

# Set environment variables (for MotherDuck/Azure)
export MOTHERDUCK_TOKEN=your-token
export DEMO_SQL_SERVER=your-server
export DEMO_SQL_USER=your-user
export DEMO_SQL_PASSWORD=your-password

# Test each target
dbt debug --profile demo_source --target dev         # Local DuckDB
dbt debug --profile demo_source --target motherduck  # MotherDuck cloud
dbt debug --profile demo_source --target azure       # Azure SQL

# Use specific target with operations
dbt run-operation demo_load_baseline --profile demo_source --target motherduck
```

### 3. Soda Core

```bash
# Install Soda Core for your platform
pip install soda-core-duckdb              # For DuckDB/MotherDuck
pip install soda-core-sqlserver           # For Azure SQL

# Copy configuration file (or customize inline)
cp extras/soda/configuration.yml soda/configuration.yml

# Edit configuration.yml:
# - For DuckDB: Uncomment the DuckDB section, set path to your .duckdb file
# - For MotherDuck: Uncomment MotherDuck section, set MOTHERDUCK_TOKEN env var
# - For Azure SQL: Uncomment Azure SQL section, set environment variables

# Run data quality checks after loading baseline
dbt run-operation demo_load_baseline --profile demo_source
soda scan -d demo_source -c extras/soda/configuration.yml extras/soda/contracts/jaffle_shop.yml
soda scan -d demo_source -c extras/soda/configuration.yml extras/soda/contracts/jaffle_crm.yml

# Run checks after applying deltas to verify data evolution
dbt run-operation demo_apply_delta --args '{day: 1}' --profile demo_source
soda scan -d demo_source -c extras/soda/configuration.yml extras/soda/contracts/jaffle_shop.yml

# What gets validated:
# - Schema: Column presence, data types, nullability
# - Foreign keys: All relationships between tables
# - Business rules: Positive quantities, valid prices, logical sequences
# - SLA/Freshness: Data is within expected time windows (60 days)
# - Soft deletes: Most records active, valid deleted_at when present
# - Duplicates: Primary keys are unique

# For Azure SQL, scan each database separately:
# 1. Set configuration.yml to database: jaffle_shop, schema: erp
#    soda scan -d demo_source -c configuration.yml contracts/jaffle_shop.yml
#
# 2. Set configuration.yml to database: jaffle_crm, schema: crm
#    soda scan -d demo_source -c configuration.yml contracts/jaffle_crm.yml

# Optional: Connect to Soda Cloud for dashboards and alerts
# - Sign up at https://cloud.soda.io
# - Add soda_cloud section to configuration.yml with API keys
```

### 4. VS Code Tasks

```bash
# Copy to your project's .vscode/ directory
mkdir -p .vscode
cp extras/vscode/tasks.json .vscode/tasks.json

# Run tasks via Command Palette:
# Cmd+Shift+P (Mac) / Ctrl+Shift+P (Windows/Linux) → "Tasks: Run Task"

# Available tasks:
# - [dbt-demo-source] Load Baseline (Day 0)
# - [dbt-demo-source] Check Status
# - [dbt-demo-source] Apply Day 1 Changes
# - [dbt-demo-source] Apply Day 2 Changes
# - [dbt-demo-source] Apply Day 3 Changes
# - [dbt-demo-source] Reset to Baseline
# - [dbt-demo-source] Full Workflow (Baseline + All 3 Days)
# - [dbt-demo-source] Verify Baseline Data

# Customize for different targets:
# Edit .vscode/tasks.json and change --profile demo_source to your profile
# Or add --target flag: --profile demo_source --target motherduck
```

### 5. Makefile / justfile

#### Option A: Makefile (traditional, widely available)

```bash
# Copy to your project root
cp extras/scripts/Makefile .

# Show all available commands
make help

# Core operations
make setup          # Install dbt package dependencies
make baseline       # Load baseline data (Day 0)
make verify         # Verify baseline was loaded correctly
make status         # Show current row counts
make delta-1        # Apply Day 1 changes
make delta-2        # Apply Day 2 changes
make delta-3        # Apply Day 3 changes
make reset          # Truncate and reload baseline

# Data quality (Soda Core)
make soda-scan      # Run quality checks on both databases
make soda-shop      # Check jaffle_shop only
make soda-crm       # Check jaffle_crm only

# Workflows (combine multiple operations)
make init           # setup + baseline + verify + status
make full-demo      # baseline + delta-1 + delta-2 + delta-3 + status
make test-workflow  # full-demo + soda-scan

# Cleanup
make clean          # Remove DuckDB database files (local only)

# Override profile or target
make baseline PROFILE=my_project
make baseline TARGET=motherduck
make baseline PROFILE=my_project TARGET=motherduck

# Configuration variables:
# - PROFILE (default: demo_source)
# - TARGET (default: dev)
# - SODA_CONFIG (default: extras/soda/configuration.yml)
```

#### Option B: justfile (modern alternative, better syntax)

```bash
# Install just: https://github.com/casey/just#installation
# macOS: brew install just
# Linux: cargo install just

# Copy to your project root
cp extras/scripts/justfile .

# Show all available recipes
just --list

# Core operations (same as Makefile)
just setup
just baseline
just verify
just status
just delta 1        # Note: justfile uses parameters instead of delta-1
just delta 2
just delta 3
just reset

# Data quality
just soda-scan
just soda-shop
just soda-crm

# Workflows
just init
just full-demo
just test-workflow

# Cleanup
just clean

# Override variables
just profile=my_project baseline
just target=motherduck baseline
just profile=my_proj target=motherduck full-demo

# Show detailed help
just help

# Advantages of justfile:
# - No tabs vs spaces issues
# - Better error messages
# - Recipe parameters (delta 1 vs delta-1)
# - Cross-platform (works on Windows)
# - Cleaner syntax
```

#### Which to use?

- **Makefile**: If your team already uses make, stick with it
- **justfile**: If starting fresh, just has better ergonomics and fewer pitfalls
- **Both**: Copy both files and let team members choose their preference

### 6. GitHub Actions

```bash
# Copy to your workflow directory
mkdir -p .github/workflows
cp extras/cicd/github-actions.yml .github/workflows/test-with-demo-sources.yml

# The workflow includes 4 jobs:
# 1. test-baseline: Load baseline and run your dbt models
# 2. test-incremental: Apply Days 1-3 and test incremental models
# 3. test-data-quality: Run Soda Core quality checks (optional)
# 4. test-matrix: Test against DuckDB and MotherDuck (requires secret)

# Required customizations in the workflow file:
# 1. Replace "my_project" with your actual dbt profile name
# 2. Update the my_project profile configuration (warehouse type, connection details)
# 3. Adjust dbt build commands for your project structure
# 4. Add your project-specific tests

# GitHub Secrets (for MotherDuck matrix testing):
# Settings → Secrets and variables → Actions → New repository secret
# - Name: MOTHERDUCK_TOKEN
# - Value: Your MotherDuck service token from https://motherduck.com

# Optional: Soda Cloud integration
# Add these secrets if you want Soda Cloud dashboards:
# - SODA_CLOUD_API_KEY_ID
# - SODA_CLOUD_API_KEY_SECRET

# Workflow triggers:
# - Runs on pull requests to main
# - Runs on pushes to main
# - Customize triggers in the workflow file's "on:" section

# What each job does:
#
# test-baseline:
#   - Loads baseline demo data (Day 0: 100 customers, 500 orders)
#   - Runs your dbt models against the demo sources
#   - Verifies data was loaded correctly
#
# test-incremental:
#   - Loads baseline, then applies Day 1, 2, and 3 deltas
#   - Tests that your incremental models handle changes correctly
#   - Useful for testing SCD Type 2, CDC, and incremental logic
#
# test-data-quality:
#   - Loads baseline and runs Soda Core quality checks
#   - Validates schema, foreign keys, business rules
#   - Applies Day 1 and re-checks to test data evolution
#
# test-matrix:
#   - Runs tests against both DuckDB (local) and MotherDuck (cloud)
#   - Ensures your models work across platforms
#   - MotherDuck requires MOTHERDUCK_TOKEN secret

# Performance tips:
# - Jobs run in parallel by default (faster CI)
# - dbt packages are cached between runs
# - Consider caching Python dependencies with setup-python cache option
# - MotherDuck cleanup step prevents database accumulation
```

---

## Customization Tips

### Profile Names
If you use a different profile name, update all examples:
```yaml
# Change from:
--profile demo_source

# To:
--profile my_project
```

### Database Names
If you override the default database names:
```yaml
# In your dbt_project.yml
vars:
  demo_source_ops:
    shop_db: 'my_shop'
    crm_db: 'my_crm'

# Update sources.yml database references accordingly
```

### Targets
All examples use `--profile demo_source` without specifying target (uses default `dev`).

To use a specific target:
```bash
# MotherDuck
dbt run-operation demo_load_baseline --profile demo_source --target motherduck

# Azure SQL
dbt run-operation demo_load_baseline --profile demo_source --target azure
```

Or override in Makefile/justfile with environment variables:
```bash
make baseline TARGET=motherduck
```

---

## Need Help?

- **Questions?** [Open an issue](https://github.com/feriksen-personal/dbt-azure-demo-source-ops/issues)
- **Wiki**: [Full documentation](https://github.com/feriksen-personal/dbt-azure-demo-source-ops/wiki)
- **Getting Started**: [Setup guide](https://github.com/feriksen-personal/dbt-azure-demo-source-ops/wiki/Getting-Started)
