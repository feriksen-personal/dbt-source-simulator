# Soda Core Configuration for dbt-origin-simulator-ops
#
# This file configures data sources for Soda Core data quality checks.
# Copy and customize for your environment.
#
# Usage:
#   soda scan -d ingestion_simulator -c extras/soda/configuration.yml extras/soda/contracts/jaffle_shop.yml
#   soda scan -d ingestion_simulator -c extras/soda/configuration.yml extras/soda/contracts/jaffle_crm.yml
#
# Installation:
#   pip install soda-core-duckdb              # For DuckDB/MotherDuck
#   pip install soda-core-sqlserver           # For Azure SQL
#   pip install soda-core-spark[databricks]   # For Databricks
#
# Documentation: https://docs.soda.io/soda-core/overview-main.html

# ============================================================================
# DuckDB (Local) - Default Configuration
# ============================================================================
# Use case: Local development, testing data quality checks
# Database files: Relative path to your DuckDB file
#
# Uncomment this section to use DuckDB:
data_source ingestion_simulator:
  type: duckdb
  path: data/ingestion_simulator.duckdb
  # schema: jaffle_shop  # No default schema - use fully qualified names in contracts

# ============================================================================
# MotherDuck (Cloud) - Collaborative Development
# ============================================================================
# Use case: Cloud collaboration, shared databases
# Requirements:
#   - MotherDuck account: https://motherduck.com
#   - Service token: https://motherduck.com (Settings → Service Tokens)
#   - Set environment variable: export MOTHERDUCK_TOKEN=your-token
#
# Uncomment this section to use MotherDuck:
# data_source ingestion_simulator:
#   type: duckdb
#   path: md:
#   token: ${MOTHERDUCK_TOKEN}
#   schema: jaffle_shop  # Default schema (use database.schema.table for other schemas)

# ============================================================================
# Azure SQL - Production-like Cloud Demos
# ============================================================================
# Use case: Cloud demos, CDC demonstrations
# Requirements:
#   - Azure SQL database provisioned
#   - Firewall rules configured
#   - Set environment variables:
#       export SQL_SERVER=your-server-name
#       export SQL_USER=your-username
#       export SQL_PASSWORD=your-password
#
# Uncomment this section to use Azure SQL:
# data_source ingestion_simulator:
#   type: sqlserver
#   host: ${SQL_SERVER}.database.windows.net
#   port: 1433
#   username: ${SQL_USER}
#   password: ${SQL_PASSWORD}
#   database: jaffle_shop  # Scans one database at a time
#   schema: erp
#   driver: ODBC Driver 18 for SQL Server
#   encrypt: true
#   trust_server_certificate: false

# ============================================================================
# Databricks - Lakehouse Data Quality
# ============================================================================
# Use case: Unity Catalog, Delta Lake quality validation
# Requirements:
#   - Databricks workspace with SQL Warehouse
#   - Personal access token generated
#   - Set environment variables:
#       export DATABRICKS_SERVER_HOSTNAME=your-workspace.cloud.databricks.com
#       export DATABRICKS_HTTP_PATH=/sql/1.0/warehouses/your-warehouse-id
#       export DATABRICKS_TOKEN=your-personal-access-token
#       export DATABRICKS_CATALOG=your-catalog-name
#
# Uncomment this section to use Databricks:
# data_source ingestion_simulator:
#   type: spark
#   method: databricks
#   host: ${DATABRICKS_SERVER_HOSTNAME}
#   http_path: ${DATABRICKS_HTTP_PATH}
#   token: ${DATABRICKS_TOKEN}
#   catalog: ${DATABRICKS_CATALOG}
#   schema: erp  # Use 'erp' for shop tables, 'crm' for CRM tables
#
# Note: Databricks uses different schema names than DuckDB:
#   - DuckDB: jaffle_shop (shop) / jaffle_crm (CRM)
#   - Databricks: erp (shop) / crm (CRM)

# ============================================================================
# Soda Cloud Integration (Optional)
# ============================================================================
# Connect to Soda Cloud for dashboards, alerts, and collaboration
# Requirements:
#   - Soda Cloud account: https://cloud.soda.io
#   - API keys from Soda Cloud (Settings → API Keys)
#
# Uncomment and configure:
# soda_cloud:
#   host: cloud.soda.io
#   api_key_id: ${SODA_CLOUD_API_KEY_ID}
#   api_key_secret: ${SODA_CLOUD_API_KEY_SECRET}

# ============================================================================
# Notes for Multi-Database Scanning (Azure SQL)
# ============================================================================
#
# For Azure SQL, you need to scan jaffle_shop and jaffle_crm separately:
#
# 1. Scan jaffle_shop:
#    - Set database: jaffle_shop, schema: erp
#    - Run: soda scan -d ingestion_simulator -c configuration.yml contracts/jaffle_shop.yml
#
# 2. Scan jaffle_crm:
#    - Update configuration: database: jaffle_crm, schema: crm
#    - Run: soda scan -d ingestion_simulator -c configuration.yml contracts/jaffle_crm.yml
#
# For DuckDB/MotherDuck, you can reference both databases in a single scan:
#    - Use fully qualified names: jaffle_shop.erp.customers, jaffle_crm.crm.campaigns
#    - Or set default schema and use database prefixes in contract files
#
# ============================================================================
# Troubleshooting
# ============================================================================
#
# Issue: "Connection failed"
# Solution: Verify environment variables are set, check network connectivity
#
# Issue: "Schema not found"
# Solution: Ensure schema matches your setup (erp for jaffle_shop, crm for jaffle_crm)
#
# Issue: "ODBC Driver 18 not found" (Azure SQL)
# Solution: Install driver from https://learn.microsoft.com/en-us/sql/connect/odbc/download-odbc-driver-for-sql-server
#
# For more help: https://github.com/feriksen-personal/dbt-origin-simulator-ops/wiki/Troubleshooting
